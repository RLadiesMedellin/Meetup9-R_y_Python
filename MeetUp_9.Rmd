---
title: "MeetUp9_Python_R"
author: "RLadies_Medellin"
date: "18/11/2021"
output:
  pdf_document: default
  html_document: default
  includes:
      in_header: estilo.tex
---

\center __Noveno Encuentro R Ladies Medellín: R y Python en el mismo lugar__

```{r message = FALSE, warning = FALSE, echo = FALSE, out.width = "70%", out.height="70%"}
library(knitr)
include_graphics("RLM.png")
```

## Nuestra actividad práctica estará dividida en tres partes:

- **Parte 1:** Pre-procesamiento de datos.
- **Parte 2:** Construcción de la red neuronal artificial.
- **Parte 3:** Evaluación del modelo y cálculo de predicciones finales.


- **Sin embargo...** Antes necesitamos inicializar Python e importar librerías necesarias.

# Inicializar Python
```{r setup, message = FALSE, warning = FALSE}
library(reticulate)
use_python('C:/Users/valen/AppData/Local/r-miniconda/envs/r-reticulate/python.exe')
py_install("scikit-learn")
py_install("keras")
py_install("tensorflow")
# reticulate::py_config()
```

### Importar librerias
```{python, warning = FALSE}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import sklearn
```
```{python, warning = FALSE, echo = FALSE}
import warnings
warnings.filterwarnings("ignore")
```

### Importar DataSet
```{python, warning = FALSE}
dataset = pd.read_csv("C:/Users/valen/Downloads/Churn_Modelling.csv")
```
# Parte 1

```{r message = FALSE, warning = FALSE, echo = FALSE, out.width = "60%", out.height="70%"}
library(knitr)
include_graphics("Pre_Processing.jpeg")
```

### Pre - procesamiento (generar la matriz de caracteristicas)
```{python, warning = FALSE}
X = dataset.iloc[:, 3:13].values
y = dataset.iloc[:, 13].values
```
### Codificar datos categóricos
```{python, warning = FALSE}
from sklearn.preprocessing import LabelEncoder

labelencoder_X_1 = LabelEncoder()
X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])
labelencoder_X_2 = LabelEncoder()
X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])
```
```{python, warning = FALSE}
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

transformer = ColumnTransformer(
    transformers=[
        ("Churn_Modelling",        
         OneHotEncoder(categories='auto'), 
         [1]            
         )
    ], remainder='passthrough'
)

X = transformer.fit_transform(X)
X = X[:, 1:]
```

### Dividir el dataset (entrenamiento y test)
```{python, warning = FALSE}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
```

### Normalizar las variables
```{python, warning = FALSE}
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
```

# Parte 2

```{r message = FALSE, warning = FALSE, echo = FALSE, out.width = "70%", out.height="70%"}
library(knitr)
include_graphics("Red.JPG")
```

### Construir la RNA
```{python, message = FALSE, warning = FALSE}

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
```

### Inicializar la RNA
```{python, warning = FALSE}
classifier = Sequential()
```
```{python, warning = FALSE, echo = FALSE}
import warnings
warnings.filterwarnings("ignore")
```

### Diseñar la RNA
```{python, message = FALSE, warning = FALSE}
# Añadir las capas de entrada y primera capa oculta
classifier.add(Dense(units = 6, kernel_initializer = "uniform",  activation = "relu", input_dim = 11))
classifier.add(Dropout(rate = 0.1))

# Añadir la segunda capa oculta
classifier.add(Dense(units = 6, kernel_initializer = "uniform",  activation = "relu"))
classifier.add(Dropout(rate = 0.1))

# Añadir la capa de salida
classifier.add(Dense(units = 1, kernel_initializer = "uniform",  activation = "sigmoid"))
```

###
###

### Compilar la RNA
```{python, warning = FALSE, message = FALSE}
classifier.compile(optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"])
classifier.fit(X_train, y_train,  batch_size = 10, epochs = 50, verbose= 0)
```

# Parte 3

```{r message = FALSE, warning = FALSE, echo = FALSE, out.width = "70%", out.height="70%"}
library(knitr)
include_graphics("ConfussionM.png")
```

### Evaluar el modelo y calcular predicciones finales
```{python, warning = FALSE}
y_pred  = classifier.predict(X_test)
y_pred = (y_pred>0.5)
```

### Elaborar la matriz de confusion
```{python, warning = FALSE}
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print((cm[0][0]+cm[1][1])/cm.sum())
```
### Ejercicio Final

- Utiliza nuestro modelo de RNA para predecir si el cliente 
con la siguiente información abandonará el banco:
- **Geografia:** Francia
- **Puntaje de crédito:** 600
- **Género:** Masculino
- **Edad:** 40 años de edad
- **Tenencia:** 3 años
- **Saldo:** $ 60000
- **Número de productos:** 2
- **¿Este cliente tiene una tarjeta de crédito?** Sí
- **¿Es este cliente un miembro activo?** Sí
- **Salario estimado:** $ 50000

```{python, warning = FALSE}
new_prediction = classifier.predict(sc_X.transform(np.array(
                                    [[0,0,600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))
print(new_prediction)
print(new_prediction > 0.5)
```

